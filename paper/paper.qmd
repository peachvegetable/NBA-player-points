---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - Yihang  Cai
thanks: "Code and data are available at: https://github.com/peachvegetable/NBA-player-points"
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
toc: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

### work space setup ###
library(tidyverse)
library(arrow)
library(tidymodels)
library(modelsummary)
library(ggplot2)
library(knitr)
library(janitor)
```


# Introduction

You can and should cross-reference sections and sub-sections. We use @citeR and @citeRohan.

The remainder of this paper is structured as follows. @sec-data....



# Data {#sec-data}


The dataset for this analysis was acquired from Basketball Reference @citeDataset and includes a wide range of NBA player statistics for the 2023-2024 season. The process of downloading this dataset involved converting the website's data table into a CSV format, then transferring this data into Excel. In Excel, I employed the 'Text to Columns' feature to separate the statistics using commas, thereby preparing the dataset for analysis. This dataset comprises a variety of player statistics, such as position, age, assists, and steals, with a total of 718 observations before any data cleaning.

The analysis was conducted in the R statistical programming environment @citeR, utilizing a selection of packages for different tasks. Data cleaning was performed using the 'Tidyverse' @citeTidyverse and 'Janitor' @citeJanitor packages, while 'Dplyr' @citeDplyr and 'Broom' @citeBroom were used for data manipulation and data frame visualization. The 'Knitr' @citeKnitr and 'Ggplot2' @citeGgplot2 packages were employed for data visualization, including the creation of tables and figures. Predictive modeling and model visualization were facilitated by the 'Tidymodels' @citeTidymodels and 'Modelsummary' @citeModelsummary packages, respectively.

The raw data is presented in @sec-raw-data, divided into four separate tables (@tbl-tbl1, @tbl-tbl2, @tbl-tbl3, @tbl-tbl4). The dataset contains 30 variables, each thoroughly introduced and explained in @sec-raw-data, offering a detailed view of the data that forms the basis of this study.


## Data processing and interested predictors

This dataset comprises statistics for players, such as 3-point goals, 2-point goals, field goals, and free throws, from which points can be derived. My objective is to forecast an NBA player's total points based on their performance metrics, indicating a direct correlation between these features and the target variable, namely, points.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-top5players
#| tbl-cap: Top 5 NBA Players Based on Select Predictors Highly Correlated with Points Scored, Season 2023-2024

# read in the raw_data
raw_data <- read_csv("../data/raw_data/raw_data.csv")

# cleans the raw_data for universal variable name and then make a table using kable function
raw_data |> 
  drop_na() |>
  clean_names() |>
  head(5) |> 
  select(player, x3p, x2p, ft, pts) |>
  rename(
    Player = player,
    "3-point goals" = x3p,
    "2-point goals" = x2p,
    "free throws" = ft,
    "points" = pts
  ) |>
  kable()
```

In @tbl-top5players, we see variables that are directly linked to a player's total points scored. For example, considering Bam Adebayo's performance in the 2023-2024 season: he scored 10 three-pointers, made 470 two-pointers, and successfully shot 276 free throws, totaling $10 \times 3 + 470 \times 2 + 276 \times 1 = 1246$ points, which exactly matches his recorded total points. To streamline the dataset for analysis, I utilized the 'tidyverse' package in R to remove these variables, which are 'fg', 'fga', 'x3p', 'x3pa', 'x2p', 'x2pa', 'ft', and 'fta'.

The dataset initially detailed players across 12 unique positions, which was quite detailed for modeling purposes. To simplify, I grouped these positions into three main categories: Guards (G): SG, PG, SG-PG, PG-SG, Forwards (F): SF, PF, PF-SF, and Centers (C): C, PF-C, C-PF. This grouping was intended to make the model clearer and to potentially improve its predictive power by reducing unnecessary complexity and avoiding overlap in variables.

Additionally, I re-evaluated the necessity of certain variables such as 'trb' (total rebounds), 'player', and 'tm' (team). 'trb', being the sum of 'orb' (offensive rebounds) and 'drb' (defensive rebounds), didn't provide additional insight and was thus omitted. The 'player' variable was removed in favor of 'rk' (rank), which sufficed for identifying players without duplicating information. Lastly, the 'tm' variable was excluded as the analysis didn't focus on team-specific performance, making the team data unnecessary for this study.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-top10players
#| tbl-cap: Top 10 NBA Players with selectely statistics, Season 2023-2024

# read in the analysis_data
analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

# show the first 10 players, and then rename some of the variables for a better view, and set the digits to two d.p. for a better view
analysis_data |>
  head(10) |>
  rename(
    'fg%' = fg_percent,
    'x3p%' = x3p_percent,
    'x2p%' = x2p_percent,
    'efg%' = e_fg_percent,
    'fg%' = fg_percent,
    'ft%' = ft_percent,
    'pos' = broad_position
  ) |>
  kable(digits = 2)
```

As illustrated in @tbl-top10players, aside from 'rk' serving as an identifier, the selected variables are central to our analysis. These will act as predictors for estimating a player's total points, considering factors such as 3-point goal percentage, position, among others. Furthermore, for enhanced clarity, the values in the tables have been formatted to display two decimal places.


# Model

This model pursues two main aims. The initial goal is to predict the total points an NBA player might score based on various performance indicators such as position and shooting efficiency. The second goal is to identify which predictors most significantly affect a player's scoring ability. For example, it is assumed that more playtime within a season could lead to a higher score.

To meet these objectives, the lasso regression model is chosen for its unique features: First, with 19 predictors left after processing the data, the lasso regression can reduce the influence of less important predictors by setting their coefficients to zero. Second, it clearly indicates which predictors have a greater impact on the scoring outcome, helping to understand what factors are most important in determining a player's points.

Lasso regression, a variant of linear regression models, is notable for its ability to select features by reducing the coefficients of less critical features to zero. This model introduces a regularization parameter, $\lambda$, which determines the strength of the penalty. This penalty minimizes some coefficients, especially those for less important variables, towards zero. As $\lambda$ increases, more coefficients are reduced to zero, leading to a simpler model. The optimal value for $\lambda$ is determined through cross-validation, ensuring the model is effectively tuned for the predictive tasks.

## Model set-up

\begin{align} 
y_i = \beta_0 + \beta_i \cdot X_i
\end{align}

In this equation, $y_i$ is the number of points a player scores, which is the dependent variable I am trying to predict. $\beta_0$ is the interception, and $\beta_i$ is a matrix that contains the coefficients $\beta_1, \beta_2, ..., \beta_{18}$ for each predictor that the lasso regression will estimate. $X_i$ is also a matrix contains the predictors: players position, age, games, game starts, minutes played, field goal percentage, 3-point field goal percentage, 2-point field goal percentage, effective field goal percentage, free throw percentage, offensive rebounds, defensive rebounds, total rebounds, assists, steals, blocks, turnovers, and personal fouls. 

We run the model in R [@citeR] using the `tidymodels` package of @citeTidymodels.

## Model justification

We anticipate a positive correlation between the points scored and several factors: age, minutes played, number of games played, games started, shooting efficiency (encompassed by 2-point goal percentage, 3-point goal percentage, field goal percentage, and free throw percentage), rebounds (both offensive and defensive), and assists. The logic is straightforward: the higher these variables, the greater the likelihood of scoring more points. Additionally, a player's position could influence their scoring, as different positions in basketball have distinct objectives; for instance, center(C) may prioritize defense over scoring.

## Model performance

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model1
#| tbl-cap: First lasso regression model top 10 predictions

first_lasso_model <- readRDS("../models/first_lasso_model.rds")

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

# data splitting
set.seed(321) # For reproducibility
data_split <- initial_split(analysis_data, prop = 0.8)
test_data <- testing(data_split)

# predictions for the first model
predictions <- predict(first_lasso_model, test_data)
results <- bind_cols(test_data, predictions)

results |>
  select(rk, pts, .pred) |>
  head(10) |>
  rename(
    "Rank" = rk,
    "Points" = pts,
    "Prediction" = .pred
    ) |>
  kable(booktabs = TRUE, digits = 2)
```
@tbl-model1 displays the predictions made by the initial lasso regression model for the number of points scored by NBA players, numbered by 'Rank' identifier. For each 'Rank', there are two columns: 'Points', which represents the actual points scored, and 'Prediction', which shows the predicted points scored by the model. It's noticeable that there's a variance between the actual points and the predicted values. The model does not seem to accurately predict the points: In some cases, such as Rank 3, the model overestimates the points, predicting 372.78 points against the actual 274. In other instances, like Rank 7, the prediction is quite close to the actual points scored (1128.62 predicted vs. 1142 actual). There are also underestimations, as seen with Rank 30, where the model predicts 985.43 points while the actual points scored are 1036. 

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model1rmsemae
#| tbl-cap: RMSE and MAE of first lasso regression model 

# read in the first lasso model
first_lasso_model <- readRDS("../models/first_lasso_model.rds")

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

# data splitting
set.seed(321) # For reproducibility
data_split <- initial_split(analysis_data, prop = 0.8)
test_data <- testing(data_split)

# predictions for the first model
predictions <- predict(first_lasso_model, test_data)
results <- bind_cols(test_data, predictions)
# Calculate RMSE for the first model
rmse_results <- rmse(results, truth = pts, estimate = .pred)
mae_results <- mae(results, pts, .pred)

results <- data.frame(
  "RMSE" = rmse_results$.estimate,
  "MAE" = mae_results$.estimate
)

rownames(results) <- "First lasso regression model"

kable(results, booktabs = TRUE, digits = 2)
```

The table @tbl-model1rmsemae lists two error metrics for assessing the first lasso regression model. RMSE(Root Mean Squared Error), recorded at 111.79, captures the average error by squaring the difference between the model's predictions and the actual points, thereby giving more weight to larger discrepancies and making it particularly useful where such errors have greater consequences. MAE(Mean Absolute Error), noted as 80.6, represents the simple average of all prediction errors without emphasis on their size, making it a reliable metric when treating all errors uniformly is preferable. Utilizing both RMSE and MAE provides a dual perspective: RMSE highlights the impact of substantial errors, and MAE offers a clear measure of average error, assisting in a balanced evaluation of the model's performance. This approach to error analysis suggests that the model's predictions could be improved by reevaluating the included features, especially in areas where the model's accuracy is critical.

### Feature engineering

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model1variables
#| tbl-cap: Top 5 important variables of the first lasso regression model

first_lasso_model <- readRDS("../models/first_lasso_model.rds")

# Extract the fitted model object
lasso_fit <- extract_fit_parsnip(first_lasso_model)

# Use broom's tidy method on the extracted fit object
coef_info <- tidy(lasso_fit)

# Now, filter out the intercept and examine the coefficients
important_predictors <- coef_info |>
  filter(term != "(Intercept)") |>
  arrange(desc(abs(estimate)))

# View the important predictors
important_predictors |>
  head(5) |>
  select(-penalty) |>
  rename(
    "Predictors" = term,
    "Coefficients" = estimate
  ) |>
  kable(booktabs = TRUE, digits = 2)
```

@tbl-model1variables lists the predictors with the highest magnitude coefficients from the lasso regression model, indicating their relative importance in predicting the outcome variable. The listed predictors are minutes played ('mp'), turnovers ('tov'), defensive rebounds ('drb'), offensive rebounds ('orb'), and personal fouls ('pf'), with their corresponding coefficients. 

The coefficient for 'mp' is positive (310.86), highlighting a direct relationship with point totals — more minutes played usually provides more opportunities for scoring. In contrast, 'orb' has a negative coefficient (-70.80), hinting at players with high offensive rebounds not necessarily correlating with higher points, perhaps indicating a focus on rebounding over scoring. 'Tov' carries a positive coefficient (225.98), which might seem counterintuitive given turnovers are adverse events; yet, it could reflect that players who handle the ball frequently might incur more turnovers and also have more scoring chances. A positive coefficient for 'drb' (73.62) suggests a link between securing defensive rebounds and higher point scores, likely due to the additional possessions gained. 'Pf' shows a negative coefficient (-65.66), indicating that fouling frequently could decrease a player's scoring by reducing playing time due to foul trouble.

To refine the model, feature engineering introduced the 'pts_per_min' predictor, combining points with minutes played to assess scoring efficiency. This reflects how well players score relative to their time on the court. 'tov_per_game' adjusts turnovers for the number of games, enabling a fairer comparison across players, and 'pf_per_game' computes the average fouls per game, a significant aspect in evaluating defensive conduct and the potential impact on game participation and point contribution. These engineered features aim to provide a clearer understanding of each player's performance, leading to an improved model with lower error metrics.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model2rmsemae
#| tbl-cap: RMSE and MAE of finalized lasso regression model 

# read in the first lasso model
second_lasso_model <- readRDS("../models/second_lasso_model.rds")

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

analysis_data <- analysis_data |>
  mutate(
    pts_per_min = pts / mp,
    tov_per_game = tov /g,
    pf_per_game = pf / g
  )

# data splitting
set.seed(123) # For reproducibility
data_split <- initial_split(analysis_data, prop = 0.8)
test_data <- testing(data_split)

# predictions for the first model
predictions <- predict(second_lasso_model, test_data)
results <- bind_cols(test_data, predictions)
# Calculate RMSE for the first model
rmse_results <- rmse(results, truth = pts, estimate = .pred)
mae_results <- mae(results, pts, .pred)

results <- data.frame(
  "RMSE" = rmse_results$.estimate,
  "MAE" = mae_results$.estimate
)

rownames(results) <- "Second lasso regression model"

kable(results, booktabs = TRUE, digits = 2)
```

As shown in @tbl-model2rmsemae, the second lasso regression model, enhanced with engineered features, has demonstrated significant improvement. The RMSE has decreased from 111.7 to 94.68, and the MAE has dropped from 80.6 to 66.14. This reduction in both metrics indicates that the model now predicts the number of points an NBA player could score based on their performances with greater precision.

# Results

Results Section Framework:
Overview of Model Performance:

Start by summarizing the overall performance of the final lasso regression model. Mention the improvement in the error metrics (RMSE and MAE) after the feature engineering, highlighting how these changes have enhanced the model's predictive accuracy.
Example: "The refinement of the lasso regression model through targeted feature engineering significantly enhanced its predictive accuracy. The RMSE decreased from 111.7 to 94.68, and the MAE improved from 80.6 to 66.14, indicating a more precise model in predicting NBA players' points based on performance metrics."
Detailed Results from Predictive Analysis:

Present specific results, such as how well the model predicted points for different players or player types. If applicable, include comparisons to show the model's performance before and after feature engineering.
Example: "Detailed analysis reveals that the model, after enhancements, provides a more accurate prediction across a range of player performance indicators, such as minutes played and turnovers. The incorporation of efficiency metrics like points per minute played ('pts_per_min') significantly contributed to this improvement."
Statistical Significance and Confidence:

Discuss any statistical tests or confidence intervals used to ascertain the reliability of the model's predictions. This could involve discussing p-values for coefficients or the confidence in the model's error metrics.
Example: "Statistical tests affirm the significance of newly integrated predictors, with p-values well below the conventional threshold of 0.05, thereby reinforcing confidence in the model's enhancements."
Visualization of Results:

If visual aids (such as plots or charts) were used to illustrate the model's performance or to compare the predicted vs. actual points, briefly describe these visualizations and their outcomes.
Example: "Graphical representations, included in fig-predictions, show a tight correlation between the model's predictions and the actual points scored, especially after the feature engineering phase."
Summary of Key Findings:

Conclude with a summary of the most critical findings from the model's application, emphasizing how these insights support the model's utility in a real-world context.
Example: "The results confirm that the enhanced lasso regression model not only predicts the point outcomes with greater accuracy but also highlights the importance of game participation metrics such as minutes played and turnovers in determining a player's scoring potential."
Additional Tips:
Clarity and Precision: Keep the language clear and precise, focusing on what the reader needs to understand about the model's performance and the significance of the results.
Referencing Tables/Graphs: Ensure to reference any tables or graphs from your analysis that support your results. This helps in validating your claims and provides a visual or tabular anchor for your findings.
Contextualization: Briefly relate your findings to the broader context of sports analytics, perhaps suggesting how these insights could influence team strategy or player evaluation.
This structure and approach should align with the academic standards outlined in the rubric, ensuring that your Results section is not only informative but also well-integrated with the rest of your paper.






# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}

# Additional data details

## Raw data {#sec-raw-data}
raw data from basketball reference is split into four tables for a better view, which are displayed below

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-tbl1
#| tbl-cap: Basic information and overall performance

# read raw_data from the folder
raw_data <- read_parquet("../data/raw_data/raw_data.parquet")

# clean it
raw_data <- raw_data |> 
  drop_na() |>
  clean_names()


# splitting the raw_data to 4 tables for a better view
tbl1 <- raw_data |>
  select(rk, player, pos, age, tm, g, gs, mp, pts) |>
  head(5) |>
  kable()

tbl1
```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-tbl2
#| tbl-cap: Shooting efficiency

# read raw_data from the folder
raw_data <- read_parquet("../data/raw_data/raw_data.parquet")

# clean it
raw_data <- raw_data |> 
  drop_na() |>
  clean_names()


# splitting the raw_data to 4 tables for a better view
tbl2 <- raw_data |>
  select(player, fg, fga, fg_percent, x3p, x3pa, x3p_percent, x2p, x2pa, x2p_percent, e_fg_percent) |>
  head(5) |>
  kable()

tbl2
```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-tbl3
#| tbl-cap: Free throws and rebounds

# read raw_data from the folder
raw_data <- read_parquet("../data/raw_data/raw_data.parquet")

# clean it
raw_data <- raw_data |> 
  drop_na() |>
  clean_names()


# splitting the raw_data to 4 tables for a better view
tbl3 <- raw_data |>
  select(player, ft, fta, ft_percent, orb, drb, trb) |>
  head(5) |>
  kable()

tbl3
```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-tbl4
#| tbl-cap: Playmaking and defence

# read raw_data from the folder
raw_data <- read_parquet("../data/raw_data/raw_data.parquet")

# clean it
raw_data <- raw_data |> 
  drop_na() |>
  clean_names()


# splitting the raw_data to 4 tables for a better view
tbl4 <- raw_data |>
  select(player, ast, stl, blk, tov, pf) |>
  head(5) |>
  kable()

tbl4
```

1. rk: rank - this doesn't represent the ranking of players based on some criterion, but purely for numbering purpose
2. player: player - the name of the basketball player.

3. pos: position - the playing position of the player.

4. age: the age of each player.

5. tm: team - the abbreviation of the NBA team the player belongs to.

6. g: games - how many games a player played in this season.

7. gs: game started - how many games a player has been in the starting lineup for their team at the beginning of the game.

8. mp: minutes played - the total time of a player played in this season.

9. fg: field goals - the total number of field goals (baskets) the player has made.

10. fga: field goal attempts - the total number of field goal shots the player has attempted.

11. fg_percent: field goal percentage - this statistic represents the percentage of field goals (both 2-pointers and 3-pointers) made by a player out of the total number of field goal attempts.

12. x3p: 3-point field goals - the total number of 3-point field goals the player has made.

13. x3pa: 3-point field goal attempts - the total number of 3-point shots the player has attempted.

14. x3p_percent: 3-point goal percentage - this statistic represents the percentage of 3-point field goals made by a player out of the total number of 3-point field goal attempts.

15. x2p: 2-point field goals - the total number of 2-point field goals the player has made.

16. x2pa: 2-point field goal attempts - the total number of 2-point shots the player has attempted.

17. x2p_percent: 2-point goal percentage - this statistic represents the percentage of 2-point field goals made by a player out of the total number of 2-point field goal attempts.

18. e_fg_percent: effective field goal percentage - this statistic adjusts for the fact that a 3-point field goal is worth more than a 2-point field goal.

19. ft: free throws - the total number of free throws the player has made.

20: fta: free throw attempts - the total number of free throw shots the player has attempted.

21. ft_percent: free throw percentage - this statistic represents the percentage of free throws made by a player out of the total number of free throw attempts.

22. orb: offensive rebounds - this statistic represents the number of rebounds grabbed by a player on the offensive end of the court.

23. drb: defensive rebounds - this statistic represents the number of rebounds grabbed by a player on the defensive end of the court.

24. trb: total rebounds - this statistic represents the total number of rebounds grabbed by a player (both offensive and defensive rebounds).

25. ast: assists - the total number of assists the player has made, indicating the number of times a player's pass led directly to a basket by a teammate.

26. stl: steals - the total number of times the player has taken the ball away from an opponent, leading to a change in possession.

27. blk: blocks - the total number of times the player has deflected an opponent's filed goal attempt, preventing the ball from going into the basket.

28. tov: turnovers - the total number of times the player has lost possession of the ball to the opposing team.

29. pf: personal fouls - the total number of personal fouls the player has committed.

30: pts: points - the total number of points the player has scored.


\newpage


# References


