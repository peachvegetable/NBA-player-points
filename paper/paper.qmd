---
title: "More Minutes, More Points â€” The Role of Aggressive Play in NBA Scoring Trends"
subtitle: "An Analysis of NBA Player Performance Using Lasso Regression for the 2023-2024 Season"
author: 
  - Yihang  Cai
thanks: "Code and data are available at: https://github.com/peachvegetable/NBA-player-points"
date: today
date-format: long
abstract: "This study applies lasso regression to predict NBA players' total points from performance metrics during the 2023-2024 season, focusing on variables such as minutes played, turnovers, and personal fouls. It was found that not only expected predictors like minutes played but also turnovers significantly affect scoring outcomes, indicating that players who engage more in the game, despite committing turnovers, tend to score higher. These insights emphasize the complex interplay between aggressive playing styles and scoring achievements. This research enriches our understanding of player performance dynamics, providing valuable knowledge for team management, player assessment, and the broader field of sports analytics."
format: pdf
number-sections: true
toc: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

### woid space setup ###
library(tidyverse)
library(arrow)
library(tidymodels)
library(modelsummary)
library(ggplot2)
library(knitr)
library(janitor)
```


# Introduction

Professional basketball is not just a display of athletic skill and competition but also a valuable area for data analysis, especially in predicting player performances. This paper examines NBA player statistics from the 2023-2024 season, aiming to predict players' total points using various performance metrics. The study utilizes lasso regression, a statistical method appreciated for its feature selection and regularization capabilities, to enhance the accuracy and simplicity of our predictive model.

This research addresses the need for a predictive model that accurately forecasts player points while demonstrating the effects of different performance metrics on scoring. The main objective is to develop a reliable model that can quantify how specific metrics influence the total points scored by NBA players.

In pursuit of this goal, the paper investigates several performance indicators such as minutes played, turnovers, rebounds, and personal fouls. Through feature engineering, these metrics are optimized for their relevance in predicting player scores. The study details the rationale behind selecting lasso regression, which reduces the influence of less critical metrics, thereby focusing on the most impactful factors.

The findings highlight that common metrics like minutes played are significant predictors of scoring potential. Interestingly, it also shows that turnovers have a positive correlation with scoring, suggesting that players involved in aggressive offensive plays tend to score higher, despite the potential risks.

These insights are vital for team strategies and player assessments and broaden the application of statistical models in sports science. They offer both theoretical and applied insights into the complex dynamics of basketball performance.

The estimand of this study, the total points a player scores, is predicted based on various processed performance metrics using lasso regression. This focus is crucial to achieving the study's goals of enhancing predictive precision and understanding how different metrics influence scoring in NBA games.

The paper is structured as follows: @sec-data covers the data collection and preparation methods; @sec-model explains the model setup, justification, and evaluation of its performance; @sec-results discusses the results; and @sec-discussion interprets these results comprehensively. Appendix provides additional data details, rounding out the discussion and ensuring thorough documentation of all methods and analyses used.

# Data {#sec-data}

The dataset for this analysis was acquired from Basketball Reference @citeDataset and includes a wide range of NBA player statistics for the 2023-2024 season. The process of downloading this dataset involved converting the website's data table into a CSV format, then transferring this data into Excel. In Excel, I employed the 'Text to Columns' feature to separate the statistics using commas, thereby preparing the dataset for analysis. This dataset comprises a variety of player statistics, such as position, age, assists, and steals, with a total of 718 observations before any data cleaning.

The analysis was conducted in the R statistical programming environment @citeR, utilizing a selection of packages for different tasks. Data cleaning was performed using the 'Tidyverse' by @citeTidyverse and 'Janitor' by @citeJanitor packages, while 'Dplyr' @citeDplyr and 'Broom' @citeBroom were used for data manipulation and data frame visualization. The 'Knitr' @citeKnitr and 'Ggplot2' @citeGgplot2 packages were employed for data visualization, including the creation of tables and figures. Predictive modeling was done by the 'Tidymodels' @citeTidymodels.

The raw data is presented in @sec-raw-data, divided into four separate tables (@tbl-tbl1, @tbl-tbl2, @tbl-tbl3, @tbl-tbl4). The dataset contains 30 variables, each thoroughly introduced and explained in @sec-raw-data, offering a detailed view of the data that forms the basis of this study.


## Data processing and interested predictors

This dataset comprises statistics for players, such as 3-point goals, 2-point goals, field goals, and free throws, which can be used to derive the number of points scored directly. Since my objective is to forecast an NBA player's total points based on their performance metrics, variables that are too closely related to the target variable, namely points should be removed.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-top5players
#| tbl-cap: Top 5 NBA Players Based on Select Predictors Highly Correlated with Points Scored, Season 2023-2024

# read in the raw_data
raw_data <- read_csv("../data/raw_data/raw_data.csv")

# cleans the raw_data for universal variable name and then make a table using kable function
raw_data |> 
  drop_na() |>
  clean_names() |>
  head(5) |> 
  select(player, x3p, x2p, ft, pts) |>
  rename(
    Player = player,
    "3-point goals" = x3p,
    "2-point goals" = x2p,
    "free throws" = ft,
    "points" = pts
  ) |>
  kable()
```

In @tbl-top5players, we see variables that are directly linked to a player's total points scored. For example, considering Bam Adebayo's performance in the 2023-2024 season: he scored 10 three-pointers, made 470 two-pointers, and successfully shot 276 free throws, totaling $10 \times 3 + 470 \times 2 + 276 \times 1 = 1246$ points, which exactly matches his recorded total points. To streamline the dataset for analysis, I utilized the 'tidyverse' package in R to remove these variables, which are 'fg', 'fga', 'x3p', 'x3pa', 'x2p', 'x2pa', 'ft', and 'fta'.

The dataset initially detailed players across 12 unique positions, which was quite detailed for modeling purposes. To simplify, I grouped these positions into three main categories: Guards (G): SG, PG, SG-PG, PG-SG, Forwards (F): SF, PF, PF-SF, and Centers (C): C, PF-C, C-PF. This grouping was intended to make the model clearer and to potentially improve its predictive power by reducing unnecessary complexity and avoiding overlap in variables.

Additionally, I re-evaluated the necessity of certain variables such as 'trb' (total rebounds), 'player', 'rk' (rank), and 'tm' (team). 'trb', being the sum of 'orb' (offensive rebounds) and 'drb' (defensive rebounds), didn't provide additional insight and was thus omitted. I also replaced 'player' and 'id' with a new variable 'id', which is sufficient for uniquely identifying players without redundancy. The 'rk' variable often duplicated because players sometimes transfer between teams within a season, making 'rk' and 'player' unreliable identifiers. Instead, I introduced 'id', assigned by row number, to effectively differentiate players across different teams, ensuring each instance is treated distinctly. Therefore, the same person in a different team would have a different id. Lastly, the 'tm' variable was excluded as the analysis didn't focus on team-specific performance, making the team data unnecessary for this study.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-top10players
#| tbl-cap: Top 10 NBA Players with selectely statistics, Season 2023-2024

# read in the analysis_data
analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

# show the first 10 players, and then rename some of the variables for a better view, and set the digits to two d.p. for a better view
analysis_data |>
  head(10) |>
  rename(
    'fg%' = fg_percent,
    'x3p%' = x3p_percent,
    'x2p%' = x2p_percent,
    'efg%' = e_fg_percent,
    'fg%' = fg_percent,
    'ft%' = ft_percent,
    'pos' = broad_position
  ) |>
  kable(digits = 0)
```

As illustrated in @tbl-top10players, aside from 'id' serving as an identifier, the selected variables are central to our analysis. These will act as predictors for estimating a player's total points, considering factors such as 3-point goal percentage, position, among others. Furthermore, for enhanced clarity, the values in the tables have been formatted to display only integers, since it is unlikely to have 0.3 point in scoring in basketball.


# Model {#sec-model}

This model pursues two main goals. The initial goal is to predict the total points an NBA player might score based on various performance indicators such as position and shooting efficiency. The second goal is to identify which predictors most significantly affect a player's scoring ability. For example, it is assumed that more playtime within a season could lead to a higher score.

To meet these objectives, the lasso regression model is chosen for its unique features: First, with 19 predictors left after processing the data, the lasso regression can reduce the influence of less important predictors by setting their coefficients to zero. Second, it clearly indicates which predictors have a greater impact on the scoring outcome, helping to understand what factors are most important in determining a player's points.

Lasso regression, a variant of linear regression models, is notable for its ability to select features by reducing the coefficients of less critical features to zero. This model introduces a regularization parameter, $\lambda$, which determines the strength of the penalty. This penalty minimizes some coefficients, especially those for less important variables, towards zero. As $\lambda$ increases, more coefficients are reduced to zero, leading to a simpler model. The optimal value for $\lambda$ is determined through cross-validation, ensuring the model is effectively tuned for the predictive tasks.

## Model set-up

\begin{align} 
y_i = \beta_0 + \beta_i \cdot X_i
\end{align}

In this equation, $y_i$ is the number of points a player scores, which is the dependent variable I am trying to predict. $\beta_0$ is the interception, which represents the average value of y when x is 0, and $\beta_i$ is a matrix that contains the coefficients $\beta_1, \beta_2, ..., \beta_{18}$ for each predictor that the lasso regression will estimate. $X_i$ is also a matrix contains the predictors: players position, age, games, game starts, minutes played, field goal percentage, 3-point field goal percentage, 2-point field goal percentage, effective field goal percentage, free throw percentage, offensive rebounds, defensive rebounds, assists, steals, blocks, turnovers, and personal fouls. ID is not included here since it's just an identifier.

We run the model in R [@citeR] using the `tidymodels` package of @citeTidymodels.

## Model justification

We anticipate a positive correlation between the points scored and several factors: minutes played, number of games played, games started, shooting efficiency (encompassed by 2-point goal percentage, 3-point goal percentage, field goal percentage, and free throw percentage), rebounds (both offensive and defensive), and assists. The logic is straightforward: the higher these variables, the greater the likelihood of scoring more points. Additionally, a player's position could influence their scoring, as different positions in basketball have distinct objectives; for instance, center(C) may prioritize defense over scoring. A negative correlation may appear between age and the number of points scored, since it would be natural to assume that an older player could be weaker than a younger player due to aging, and thus scores less.

## Model performance

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model1
#| tbl-cap: First lasso regression model top 10 predictions

first_lasso_model <- readRDS("../models/first_lasso_model.rds")

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

# data splitting
set.seed(123) # For reproducibility
data_split <- initial_split(analysis_data, prop = 0.8)
test_data <- testing(data_split)

# predictions for the first model
predictions <- predict(first_lasso_model, test_data)
results <- bind_cols(test_data, predictions)

results |>
  select(id, pts, .pred) |>
  head(10) |>
  rename(
    "ID" = id,
    "Points" = pts,
    "Prediction" = .pred
    ) |>
  kable(booktabs = TRUE, digits = 0)
```
@tbl-model1 displays the predictions made by the initial lasso regression model for the number of points scored by NBA players, numbered by 'ID' identifier. For each 'ID', there are two columns: 'Points', which represents the actual points scored, and 'Prediction', which shows the predicted points scored by the model. It's noticeable that there's a variance between the actual points and the predicted values. The model does not seem to accurately predict the points: In some cases, such as ID 9, the model overestimates the points, predicting 701 points against the actual 563. In other instances, like ID 2, the prediction is quite close to the actual points scored (184 predicted vs. 193 actual). There are also unrealistic estimations, as seen with ID 15, where the model predicts -1 points while the actual points scored are 26, which it is impossible to have negative points scored in basketball. 

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model1rmsemae
#| tbl-cap: RMSE and MAE of first lasso regression model 

# read in the first lasso model
first_lasso_model <- readRDS("../models/first_lasso_model.rds")

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

# data splitting
set.seed(321) # For reproducibility
data_split <- initial_split(analysis_data, prop = 0.8)
test_data <- testing(data_split)

# predictions for the first model
predictions <- predict(first_lasso_model, test_data)
results <- bind_cols(test_data, predictions)
# Calculate RMSE for the first model
rmse_results <- rmse(results, truth = pts, estimate = .pred)
mae_results <- mae(results, pts, .pred)

results <- data.frame(
  "RMSE" = rmse_results$.estimate,
  "MAE" = mae_results$.estimate
)

rownames(results) <- "First lasso regression model"

kable(results, booktabs = TRUE, digits = 2)
```

@tbl-model1rmsemae lists two error metrics for assessing the first lasso regression model. RMSE(Root Mean Squared Error), recorded at 110.12, captures the average error by squaring the difference between the model's predictions and the actual points, thereby giving more weight to larger discrepancies and making it particularly useful where such errors have greater consequences. MAE(Mean Absolute Error), noted as 78.23, represents the simple average of all prediction errors without emphasis on their size, making it a reliable metric when treating all errors uniformly is preferable. Utilizing both RMSE and MAE provides a dual perspective: RMSE highlights the impact of substantial errors, and MAE offers a clear measure of average error, assisting in a balanced evaluation of the model's performance. This approach to error analysis suggests that the model's predictions could be improved by re-evaluating the included features, especially in areas where the model's accuracy is critical.

### Feature engineering

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model1variables
#| tbl-cap: Top 5 important variables of the first lasso regression model

first_lasso_model <- readRDS("../models/first_lasso_model.rds")

# Extract the fitted model object
lasso_fit <- extract_fit_parsnip(first_lasso_model)

# Use broom's tidy method on the extracted fit object
coef_info <- tidy(lasso_fit)

# Now, filter out the intercept and examine the coefficients
important_predictors <- coef_info |>
  filter(term != "(Intercept)") |>
  arrange(desc(abs(estimate)))

# View the important predictors
important_predictors |>
  head(5) |>
  select(-penalty) |>
  rename(
    "Predictors" = term,
    "Coefficients" = estimate
  ) |>
  kable(booktabs = TRUE, digits = 0)
```

@tbl-model1variables lists the predictors with the highest magnitude coefficients from the lasso regression model, indicating their relative importance in predicting the outcome variable. The listed predictors are minutes played ('mp'), turnovers ('tov'), defensive rebounds ('drb'), offensive rebounds ('orb'), and personal fouls ('pf'), with their corresponding coefficients. 

The coefficient for 'mp' is positive (305), highlighting a direct relationship with point totals â€” more minutes played usually provides more opportunities for scoring. In contrast, 'orb' has a negative coefficient (-60), hinting at players with high offensive rebounds not necessarily correlating with higher points, perhaps indicating a focus on rebounding over scoring. 'tov' carries a positive coefficient (209), which might seem counterintuitive given turnovers are adverse events; yet, it could reflect that players who handle the ball frequently might incur more turnovers and also have more scoring chances. A positive coefficient for 'drb' (71) suggests a link between securing defensive rebounds and higher point scores, likely due to the additional possessions gained. 'pf' shows a negative coefficient (-58), indicating that fouling frequently could decrease a player's scoring by reducing playing time due to foul trouble.

To refine the model, feature engineering introduced the 'pts_per_min' predictor, combining points with minutes played to assess scoring efficiency. This reflects how well players score relative to their time on the court. 'tov_per_game' adjusts turnovers for the number of games, enabling a fairer comparison across players, and 'pf_per_game' computes the average fouls per game, a significant aspect in evaluating defensive conduct and the potential impact on game participation and point contribution. 

To guarantee that the final lasso regression model's predictions stay within realistic limits, we've implemented a simple yet deliberate adjustment: all negative predicted values are set to zero. While this approach may appear overly simplistic, it is employed for considered reasons that will be elaborated upon in the Discussion section (@sec-discussion).

These engineered features aim to provide a clearer understanding of each player's performance, leading to an improved model with lower error metrics.

# Results {#sec-results}

## Model overview

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model2rmsemae
#| tbl-cap: RMSE and MAE of finalized lasso regression model 

# read in the first lasso model
second_lasso_model <- readRDS("../models/second_lasso_model.rds")

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

analysis_data <- analysis_data |>
  mutate(
    pts_per_min = pts / mp,
    tov_per_game = tov /g,
    pf_per_game = pf / g
  )

# data splitting
set.seed(123) # For reproducibility
data_split <- initial_split(analysis_data, prop = 0.8)
test_data <- testing(data_split)

# predictions for the first model
predictions <- predict(second_lasso_model, test_data) 

predictions[predictions < 0] <- 0

results <- bind_cols(test_data, predictions)
# Calculate RMSE for the first model
rmse_results <- rmse(results, truth = pts, estimate = .pred)
mae_results <- mae(results, pts, .pred)

results <- data.frame(
  "RMSE" = rmse_results$.estimate,
  "MAE" = mae_results$.estimate
)

rownames(results) <- "Second lasso regression model"

kable(results, booktabs = TRUE, digits = 2)
```

As shown in @tbl-model2rmsemae, the second lasso regression model, enhanced with engineered features, has demonstrated significant improvement. The RMSE has decreased from 110.12 to 91.03, and the MAE has dropped from 78.23 to 60.8. This reduction in both metrics indicates that the model now predicts the number of points an NBA player could score based on their performances with greater precision. 

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model2
#| tbl-cap: Final lasso regression model top 10 predictions

second_lasso_model <- readRDS("../models/second_lasso_model.rds")

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

analysis_data <- analysis_data |>
  mutate(
    pts_per_min = pts / mp,
    tov_per_game = tov /g,
    pf_per_game = pf / g
  )

# data splitting
set.seed(123) # For reproducibility
data_split <- initial_split(analysis_data, prop = 0.8)
test_data <- testing(data_split)

# predictions for the first model
predictions <- predict(second_lasso_model, test_data)

predictions[predictions < 0] <- 0
  
results <- bind_cols(test_data, predictions)

results |>
  select(id, pts, .pred) |>
  head(10) |>
  rename(
    "ID" = id,
    "Points" = pts,
    "Prediction" = .pred
    ) |>
  kable(booktabs = TRUE, digits = 0)
```

@tbl-model2 presents the comparison of actual points scored by players against the points predicted by our refined lasso regression model. For each player, designated by a ID, the table lists both the actual and predicted points, showcasing the model's predictions. For example, a player at ID 1 is shown with an actual score of 552 and a closely aligned prediction of 558. Similarly, for a player at ID 56 with an actual score of 114, the model predicts a nearly precise 107 points, and another at ID 3 has an actual score of 359 with a prediction of 342, reflecting the model's accuracy.

When we compare this to the predictions in @tbl-model1, we notice a substantial improvement. Previously, for a player ID 9, the model had overestimated with a prediction of 701 points, which was quite higher than the actual, and for a player ID 15 the model had an unrealistic estimation of -1. In contrast, @tbl-model2 shows a more accurate and realistic prediction, indicating that the model has been better tuned.

However, in @tbl-model2, there are instances where predictions have been adjusted to 0, such as at ID 15 and 44. This adjustment, while necessary to avoid negative predictions, could introduce bias. Further explanation and exploration of this methodological choice will be provided in @sec-discussion of the paper.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-model1model2
#| fig-cap: Comparison of first model prediction and second model prediction

# first model
first_lasso_model <- readRDS("../models/first_lasso_model.rds")

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

# data splitting
set.seed(123) # For reproducibility
data_split <- initial_split(analysis_data, prop = 0.8)
test_data <- testing(data_split)

# predictions for the first model
predictions <- predict(first_lasso_model, test_data)
results <- bind_cols(test_data, predictions)
first_predictions <- results |>
  select(id, pts, .pred) |>
  rename(First_Prediction = .pred)

# second model
second_lasso_model <- readRDS("../models/second_lasso_model.rds")

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

analysis_data <- analysis_data |>
  mutate(
    pts_per_min = pts / mp,
    tov_per_game = tov /g,
    pf_per_game = pf / g
  )

# data splitting
set.seed(123) # For reproducibility
data_split <- initial_split(analysis_data, prop = 0.8)
test_data <- testing(data_split)

# predictions for the first model
predictions <- predict(second_lasso_model, test_data)

predictions[predictions < 0] <- 0
  
results <- bind_cols(test_data, predictions)

second_predictions <- results |>
  select(id, pts, .pred) |>
  rename(Second_Prediction = .pred)

# Combine the first and second predictions with the actual points
combined_predictions <- test_data |>
  select(id, pts) |>
  mutate(
    First_Prediction = first_predictions$First_Prediction,
    Second_Prediction = second_predictions$Second_Prediction
  )

# Combine the first and second predictions with the actual points
ggplot(combined_predictions, aes(x = pts)) +
  geom_point(aes(y = First_Prediction, color = "First Model"), alpha = 0.5) +
  geom_point(aes(y = Second_Prediction, color = "Second Model"), alpha = 0.5) +
  labs(
    x = "Actual Points",
    y = "Predicted Points",
    color = "Model"
  ) +
  theme_minimal() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  scale_color_manual(values = c("First Model" = "blue", "Second Model" = "green")) +
  theme(legend.position = "bottom")
```
@fig-model1model2 is a scatter plot, which illustrates a comparison between actual points scored by players and predictions made by two different lasso regression models. The x-axis denotes the actual points, while the y-axis corresponds to the predicted points from each model. The green dots, representing predictions from the second model, are observed to cluster more closely to the red dashed line, which signifies perfect accuracy where predicted points match actual points. This clustering indicates that the second model generally has better predictive accuracy compared to the first model, whose predictions are denoted by the other color, perhaps blue, and may not cluster as tightly around this line of accuracy. However, it can be seen from the figure that the predictions made by the second model are further from the actual values compare with the predictions made by the first model. The possible reason will be discussed in @sec-discussion.

## Important predictors

According to @tbl-model1variables, predictors 'mp' and 'tov' are the most important variables that contribute to the prediction of number of points as indicated by their coefficients in the model (305 and 209 respectively, much higher than the other three variables). To explore how these variables correlate with the scoring outcome, scatter plots were made to display their relationships with the target variable number of points.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-variables
#| fig-cap: Impact of player performance metrics on scoring across key statistical relationships
#| fig-subcap: ["minutes played vs points", "turnovers vs points"]
#| layout-ncol: 2

# Load the data
analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

# Plotting the relationship between minutes played (mp) and points (pts)
ggplot(analysis_data, aes(x = mp, y = pts)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(
    x = "Minutes Played (mp)",
    y = "Points Scored (pts)"
  ) +
  theme_minimal()

# Plotting the relationship between turnovers (tov) and points (pts)
ggplot(analysis_data, aes(x = tov, y = pts)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(
    x = "Turnovers (tov)",
    y = "Points Scored (pts)"
  ) +
  theme_minimal()
```

@fig-variables illustrates the relationships between various performance metrics and the total points scored by players, with each plot featuring a distinct statistical category. The linear trend lines, maided in red, offer a visual summary of each relationship. @fig-variables-1 shows a positive correlation between the minutes played ('mp') and the points scored ('pts'). The upward trend suggests that players who spend more time on the court tend to score more points. This is intuitive and proves our assumption as more playing time offers more opportunities to score. @fig-variables-2 displays the relationship between turnovers ('tov') and points scored also appears to be positive. Typically, turnovers are considered negative events; however, this positive trend may imply that players who are more involved in action-packed facets of the game tend to score higher, even though they might also commit more turnovers.

The importance of these variables in predicting the number of points scored is underpinned by their direct and indirect contributions to a player's impact on the game. Minutes played directly increases opportunities for scoring, and turnovers may indicate a player's involvement in high-risk, high-reward plays. These findings support the decision to include these variables in the predictive model because they play a significant role in predicting the number of points scored.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-ageblk
#| fig-cap: Less important performance metrics on points prediction
#| fig-subcap: ["age vs points", "blocks vs points"]
#| layout-ncol: 2

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

ggplot(analysis_data, aes(x = age, y = pts)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(
    x = "Age",
    y = "Points Scored (pts)"
  ) +
  theme_minimal()

ggplot(analysis_data, aes(x = blk, y = pts)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(
    x = "Blocks (blk)",
    y = "Points Scored (pts)"
  ) +
  theme_minimal()
```

Similarly, @fig-ageblk provides scatter plots that illustrate the relationships of age and blocks with points scored. I made a naive assumption that older players may score less than younger players, since in basketball, the physical demands on players can lead to a decline in performance as they age. Older players may score fewer points compared to their younger counterparts, primarily due to the cumulative effects of wear and tear on their bodies from multiple seasons of intense competition. This decline is often exacerbated by injuries that become more prevalent and harder to recover from with age. As players experience more seasons, the stress of high-intensity games can lead to persistent health issues, which may significantly impact their ability to maintain peak performance levels, particularly in scoring. However, @fig-ageblk-1 shows that there isn't a noticeable trend between age and points scored, which contradicts with my assumption. This could be due to the following reasons: first, as players age, they often adapt their playing style to stay competitive. Veterans might shift to roles that require less physical exertion or focus on aspects of the game that rely more on experience and skill rather than physicality. Secondly, modern training methods, diet, and medical treatments can prolong a player's peak performance. Players might maintain a high level of play longer than in the past due to better overall health and fitness management. Lastly, the most important factor could be that the cumulative knowledge and skills acquired from years of playing can help older players adapt and find new ways to score, effectively balancing out the physical challenges of aging. 

Moreover, @fig-ageblk-2 shows that the relation between number of blocks and points scored is weak, indicating that some players have different roles than others, which may focus on defenses and assistance rather than scoring. 

# Discussion {#sec-discussion}

The ability to predict player performance metrics in sports is a critical aspect of team management and strategy development. In this paper, we've created a model that accurately forecasts NBA players' total points using a variety of performance metrics.

## Model summary and modifications

In this paper, we have applied a lasso regression model, a recognized method in statistics, to estimate the total points scored by NBA players from their performance statistics. This approach was selected for its ability to handle numerous predictors and its efficiency in shrinking less relevant predictors' coefficients towards zero, thus simplifying the model.

We refined the model through feature engineering, a crucial step in which we derived new variables such as points per minute played, turnovers per game, and personal fouls per game. These variables were specifically constructed to capture the efficiency and impact of a playerâ€™s performance relative to their time on the court and their involvement in the game. Moreover, we addressed the issue of negative predictionsâ€”impossible in the real-world context of point scoringâ€”by setting a floor value of zero. While these modifications led to improvements in predictive accuracy, they also introduced certain limitations that we'll discuss subsequently.

## Key Predictive Variables

Our findings reveal that minutes played, turnovers, total rebounds, and personal fouls hold substantial predictive power for determining a player's total points. These variables contribute significantly to a playerâ€™s performance score, with minutes played emerging as a particularly potent predictor. This aligns with the intuitive understanding that more time on the court allows for more opportunities to score.

## Weaknesses

The study's methodology presents several weaknesses. Firstly, the potential non-linear relationships between some predictors and the total points scored are not fully captured by the lasso regression model. This could lead to an oversimplification of the complex dynamics of basketball performance. Secondly, the method of setting negative predictions to zero, though it ensures realistic prediction values, might reduce the model's accuracy as it deviates from true statistical adjustments, such as those achievable through log transformation. Thirdly, limiting the analysis to data points below a threshold of 1000 points may obscure the model's performance at the higher end of the spectrum. Lastly, the removal of the 'tm' (team) variable could ignore the potential change of players' performance across different teams, potentially affecting model's prediction.

## Next steps

To build upon this study's foundation, future research should consider incorporating data from multiple seasons to provide a more robust training set for the model, potentially capturing more subtle patterns in player performance over time. Including the 'tm' variable in the analysis might offer insights into how team dynamics influence individual performance. Further exploration into non-linear modeling techniques could also better accommodate the complex relationships within the data.

\newpage

\appendix

# Appendix {-}

# Additional data details

## Raw data {#sec-raw-data}
raw data from basketball reference is split into four tables for a better view, which are displayed below

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-tbl1
#| tbl-cap: Basic information and overall performance

# read raw_data from the folder
raw_data <- read_parquet("../data/raw_data/raw_data.parquet")

# clean it
raw_data <- raw_data |> 
  drop_na() |>
  clean_names()


# splitting the raw_data to 4 tables for a better view
tbl1 <- raw_data |>
  select(rk, player, pos, age, tm, g, gs, mp, pts) |>
  head(5) |>
  kable()

tbl1
```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-tbl2
#| tbl-cap: Shooting efficiency

# read raw_data from the folder
raw_data <- read_parquet("../data/raw_data/raw_data.parquet")

# clean it
raw_data <- raw_data |> 
  drop_na() |>
  clean_names()


# splitting the raw_data to 4 tables for a better view
tbl2 <- raw_data |>
  select(player, fg, fga, fg_percent, x3p, x3pa, x3p_percent, x2p, x2pa, x2p_percent, e_fg_percent) |>
  head(5) |>
  kable()

tbl2
```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-tbl3
#| tbl-cap: Free throws and rebounds

# read raw_data from the folder
raw_data <- read_parquet("../data/raw_data/raw_data.parquet")

# clean it
raw_data <- raw_data |> 
  drop_na() |>
  clean_names()


# splitting the raw_data to 4 tables for a better view
tbl3 <- raw_data |>
  select(player, ft, fta, ft_percent, orb, drb, trb) |>
  head(5) |>
  kable()

tbl3
```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-tbl4
#| tbl-cap: Playmaking and defence

# read raw_data from the folder
raw_data <- read_parquet("../data/raw_data/raw_data.parquet")

# clean it
raw_data <- raw_data |> 
  drop_na() |>
  clean_names()


# splitting the raw_data to 4 tables for a better view
tbl4 <- raw_data |>
  select(player, ast, stl, blk, tov, pf) |>
  head(5) |>
  kable()

tbl4
```

1. id: rank - this doesn't represent the ranking of players based on some criterion, but purely for numbering purpose
2. player: player - the name of the basketball player.

3. pos: position - the playing position of the player.

4. age: the age of each player.

5. tm: team - the abbreviation of the NBA team the player belongs to.

6. g: games - how many games a player played in this season.

7. gs: game started - how many games a player has been in the starting lineup for their team at the beginning of the game.

8. mp: minutes played - the total time of a player played in this season.

9. fg: field goals - the total number of field goals (baskets) the player has made.

10. fga: field goal attempts - the total number of field goal shots the player has attempted.

11. fg_percent: field goal percentage - this statistic represents the percentage of field goals (both 2-pointers and 3-pointers) made by a player out of the total number of field goal attempts.

12. x3p: 3-point field goals - the total number of 3-point field goals the player has made.

13. x3pa: 3-point field goal attempts - the total number of 3-point shots the player has attempted.

14. x3p_percent: 3-point goal percentage - this statistic represents the percentage of 3-point field goals made by a player out of the total number of 3-point field goal attempts.

15. x2p: 2-point field goals - the total number of 2-point field goals the player has made.

16. x2pa: 2-point field goal attempts - the total number of 2-point shots the player has attempted.

17. x2p_percent: 2-point goal percentage - this statistic represents the percentage of 2-point field goals made by a player out of the total number of 2-point field goal attempts.

18. e_fg_percent: effective field goal percentage - this statistic adjusts for the fact that a 3-point field goal is worth more than a 2-point field goal.

19. ft: free throws - the total number of free throws the player has made.

20: fta: free throw attempts - the total number of free throw shots the player has attempted.

21. ft_percent: free throw percentage - this statistic represents the percentage of free throws made by a player out of the total number of free throw attempts.

22. orb: offensive rebounds - this statistic represents the number of rebounds grabbed by a player on the offensive end of the court.

23. drb: defensive rebounds - this statistic represents the number of rebounds grabbed by a player on the defensive end of the court.

24. trb: total rebounds - this statistic represents the total number of rebounds grabbed by a player (both offensive and defensive rebounds).

25. ast: assists - the total number of assists the player has made, indicating the number of times a player's pass led directly to a basket by a teammate.

26. stl: steals - the total number of times the player has taken the ball away from an opponent, leading to a change in possession.

27. blk: blocks - the total number of times the player has deflected an opponent's filed goal attempt, preventing the ball from going into the basket.

28. tov: turnovers - the total number of times the player has lost possession of the ball to the opposing team.

29. pf: personal fouls - the total number of personal fouls the player has committed.

30: pts: points - the total number of points the player has scored.


\newpage


# References


weaknesses: position grouping; discussion: less important variables, like blk not served as scorer, age

